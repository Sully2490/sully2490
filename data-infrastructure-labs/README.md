# Data Infrastructure Labs

Reusable infrastructure patterns and tools for data engineering. Each lab is a standalone project that solves a specific infrastructure problem — streaming, storage, CI/CD, or data quality.

**Tech Stack:** Python | SQL | Apache Airflow | Kafka | AWS | Docker | Terraform

---

## Projects

| # | Project | Description | Status |
|---|---------|-------------|--------|
| 01 | [Streaming Pipeline](./01-streaming-pipeline) | Real-time data streaming with Kafka, including producers, consumers, and stream processing | Planned |
| 02 | [Data Lake](./02-data-lake) | S3-based data lake with partitioning, cataloging (Glue), and query layer (Athena) | Planned |
| 03 | [CI/CD Pipeline](./03-cicd-pipeline) | Automated testing, linting, and deployment pipeline for data projects | Planned |
| 04 | [Data Quality Framework](./04-data-quality-framework) | Reusable data validation and quality checks with Great Expectations or custom framework | Planned |

---

## Purpose

These aren't domain-specific projects — they're the building blocks. Every pipeline needs reliable streaming, storage, deployment, and quality checks. This repo isolates those concerns so they can be built right and reused across projects.

---

## About

Built by an Army veteran applying engineering discipline to data infrastructure. Clean patterns, tested code, documented decisions.
